{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mp_report2 사용시 content와 ngram 열에 리스트가 str으로 변환되어 들어감.\n",
    "# 특수 문자 제거과정 거쳐 mp_clean 생성 \n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "mp_clean = pd.read_csv('mp_report2.csv')\n",
    "mp_clean\n",
    "\n",
    "for i in range(len(mp_sent)):\n",
    "    try: \n",
    "        mp_clean['content'][i] = re.sub(r\"\\(|\\)|\\[|\\]|\\'|-|｢|｣|•\", \"\", mp_clean['content'][i])\n",
    "        mp_clean['ngram'][i] = re.sub(r\"\\[|\\]|\\'\", \"\", mp_clean['ngram'][i])\n",
    "        print(i)\n",
    "    except:\n",
    "        print(\"failed\")\n",
    "        pass\n",
    "    \n",
    "\n",
    "mp_clean.to_csv('mp_clean.csv', index=False)\n",
    "mp_clean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. 정제된 금통위의사록 데이터프레임 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from ekonlpy.sentiment import MPCK\n",
    "\n",
    "mpck = MPCK()\n",
    "mp_clean = pd.read_csv('mp_clean.csv') # ngra 컬럼 사용x content만 추출\n",
    "mp_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. 문장별 톤 구하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 문장 별 ngram 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_total = []\n",
    "for i in range(len(mp_clean)):\n",
    "    mp_part = []\n",
    "    for j in range(len(mp_clean['content'][i].split('.'))):\n",
    "        text = mp_clean['content'][i].split('.')[j]\n",
    "        tokens = mpck.tokenize(text) #토큰 리스트\n",
    "        ngrams = mpck.ngramize(tokens) #엔그램 리스트\n",
    "        ngram_list = []\n",
    "        for k in range(len(tokens)):\n",
    "            ngram_list.append(tokens[k])\n",
    "        for l in range(len(ngrams)):\n",
    "            ngram_list.append(ngrams[l])\n",
    "        mp_part.append(ngram_list)\n",
    "    mp_total.append(mp_part)\n",
    "mp_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 문장 별 어조 구하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#각 문장의 어조 csv추출\n",
    "neg_dic = pd.read_csv('close_neg_dic.csv', encoding = 'utf-8')\n",
    "pos_dic = pd.read_csv('close_pos_dic.csv', encoding = 'utf-8')\n",
    "#부정사전 리스트(금리 인하, Dovish)\n",
    "negative_list = []\n",
    "for i in range(len(neg_dic)):\n",
    "    negative_list.append(neg_dic['ngram'][i])\n",
    "#긍정사전 리스트(금리 인상, Hawkish)\n",
    "positive_list = []\n",
    "for i in range(len(pos_dic)):\n",
    "    positive_list.append(pos_dic['ngram'][i])\n",
    "#어조 분석\n",
    "tone_list = [] #각 의사록별 톤 리스트 도출\n",
    "for i in range(len(mp_total)): #각 의사록\n",
    "    negative_sentence = 0\n",
    "    positive_sentence = 0\n",
    "    for j in range(len(mp_total[i])): #각 문장 -> 문장의 sentence_tone을 도출\n",
    "        negative_word = 0\n",
    "        positive_word = 0\n",
    "        for k in range(len(mp_total[i][j])): #각 문장의 단어들\n",
    "            if mp_total[i][j][k] in negative_list:\n",
    "                negative_word += 1\n",
    "            elif mp_total[i][j][k] in positive_list:\n",
    "                positive_word += 1\n",
    "            else:\n",
    "                pass\n",
    "        try:\n",
    "            sentence_tone = (positive_word - negative_word) / (positive_word + negative_word)\n",
    "        except:\n",
    "            sentence_tone = 0\n",
    "        if sentence_tone > 0:\n",
    "            positive_sentence += 1\n",
    "        elif sentence_tone < 0:\n",
    "            negative_sentence += 1\n",
    "        else:\n",
    "            pass\n",
    "    try:\n",
    "        document_tone = (positive_sentence - negative_sentence) / (positive_sentence + negative_sentence)\n",
    "        tone_list.append(document_tone)\n",
    "    except:\n",
    "        document_tone = 0  #각 의사록별 document_tone을 도출\n",
    "        tone_list.append(document_tone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_tone = pd.DataFrame(index=range(0,len(mp_clean)), columns=['date','TONE-Doc'])\n",
    "                       \n",
    "mp_tone['date'] = mp_clean['date']\n",
    "mp_tone['TONE-Doc'] = tone_list\n",
    "\n",
    "mp_tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어조 데이터프레임에 기준금리 열 추가\n",
    "base_rate = pd.read_csv(\"base_rate.csv\", encoding = \"utf-8\")\n",
    "mp_tone = pd.merge(mp_tone,base_rate, on='date',how='left')\n",
    "mp_tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 의사록 어조와 기준금리 간의 상관관계 측정\n",
    "corr = mp_tone.corr()\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. get score(논문 저자들이 사용한 함수)와 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ekonlpy.sentiment import MPKO\n",
    "mpko = MPKO()\n",
    "\n",
    "#각 문장의 어조 csv추출\n",
    "neg_dic = pd.read_csv('close_neg_dic.csv', encoding = 'utf-8')\n",
    "pos_dic = pd.read_csv('close_pos_dic.csv', encoding = 'utf-8')\n",
    "#부정사전 리스트(금리 인하, Dovish)\n",
    "negative_list = []\n",
    "for i in range(len(neg_dic)):\n",
    "    negative_list.append(neg_dic['ngram'][i])\n",
    "#긍정사전 리스트(금리 인상, Hawkish)\n",
    "positive_list = []\n",
    "for i in range(len(pos_dic)):\n",
    "    positive_list.append(pos_dic['ngram'][i])\n",
    "#어조 분석\n",
    "tone_list2 = [] #각 의사록별 톤 리스트 도출\n",
    "for i in range(len(mp_total)): #각 의사록\n",
    "    negative_sentence = 0\n",
    "    positive_sentence = 0\n",
    "    for j in range(len(mp_total[i])): #각 문장 -> 문장의 sentence_tone을 도출\n",
    "        text = mp_total[i][j]\n",
    "        tokens = mpko.tokenize(text)  \n",
    "        sentence_tone = mpko.get_score(tokens)['Polarity']\n",
    "        if sentence_tone > 0:\n",
    "            positive_sentence += 1\n",
    "        elif sentence_tone < 0:\n",
    "            negative_sentence += 1\n",
    "        else:\n",
    "            pass\n",
    "    try:\n",
    "        document_tone = (positive_sentence - negative_sentence) / (positive_sentence + negative_sentence)\n",
    "        tone_list2.append(document_tone)\n",
    "    except:\n",
    "        document_tone = 0  #각 의사록별 document_tone을 도출\n",
    "        tone_list2.append(document_tone)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_tone2 = pd.DataFrame(index=range(0,len(mp_clean)), columns=['date','TONE-Doc'])                      \n",
    "mp_tone2['date'] = mp_clean['date']\n",
    "mp_tone2['TONE-Doc'] = tone_list2\n",
    "mp_tone2 = pd.merge(mp_tone2,base_rate, on='date',how='left')\n",
    "mp_tone2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = mp_tone2.corr()\n",
    "print(corr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
